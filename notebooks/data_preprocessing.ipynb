{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df37ec0a-eb0a-442f-8cd0-25f6689ae564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "import string\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f08ec3ff-67db-4cc9-b474-0ab504cc839d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I caught this little gem totally by accident b...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I can't believe that I let myself into this mo...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>*spoiler alert!* it just gets to me the nerve ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If there's one thing I've learnt from watching...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I remember when this was in theaters, reviews ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  I caught this little gem totally by accident b...  positive\n",
       "1  I can't believe that I let myself into this mo...  negative\n",
       "2  *spoiler alert!* it just gets to me the nerve ...  negative\n",
       "3  If there's one thing I've learnt from watching...  negative\n",
       "4  I remember when this was in theaters, reviews ...  negative"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df = pd.read_csv(\"../data/raw/final_project_train_dataset/train.csv\", sep=',')\n",
    "reviews_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbae39ad-f30e-4f0a-8e11-42ce4f267881",
   "metadata": {},
   "source": [
    "# Dataset preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5420ce-e763-4839-9d73-d9905b54d280",
   "metadata": {},
   "source": [
    "## Main features extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "007b7df4-1816-41b3-8dc3-fca84d336ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df['number_of_chars'] = reviews_df['review'].apply(len)\n",
    "reviews_df['percentage_of_signs'] = reviews_df['review'].apply(lambda x: sum([1 for c in x if not c.isalpha()]) / len(x) * 100)\n",
    "reviews_df['number_of_excl_marks'] = reviews_df['review'].apply(lambda x: x.count('!'))\n",
    "reviews_df['number_of_question_marks'] = reviews_df['review'].apply(lambda x: x.count('?'))\n",
    "reviews_df['number_of_ellipses'] = reviews_df['review'].apply(lambda x: x.count('...'))\n",
    "reviews_df['number_of_uppercase_words'] = reviews_df['review'].apply(lambda x: sum([1 for w in x.split() if re.sub(r'[^a-zA-Z]', '', w).isupper()]))\n",
    "\n",
    "numerical_review_features = [\n",
    "    'number_of_chars',\n",
    "    'percentage_of_signs',\n",
    "    'number_of_excl_marks',\n",
    "    'number_of_question_marks',\n",
    "    'number_of_ellipses',\n",
    "    'number_of_uppercase_words'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe9c0b6-06d0-43cf-a3d2-5fb23ace14b1",
   "metadata": {},
   "source": [
    "## Duplicates removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd6526a0-9996-4fb0-8255-e6c62b47fd5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd3e7220-5bd1-49e8-b79c-247c4a964c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39728"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.drop_duplicates(inplace=True)\n",
    "len(reviews_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a9b9d7-46bc-4bbb-9683-844a0eb3b877",
   "metadata": {},
   "source": [
    "## Outliers removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33cf85a8-eca9-4e91-9ed9-96aabe3d74e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>number_of_chars</th>\n",
       "      <td>39728.0</td>\n",
       "      <td>1311.359469</td>\n",
       "      <td>988.798970</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>971.500000</td>\n",
       "      <td>1596.000000</td>\n",
       "      <td>13704.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percentage_of_signs</th>\n",
       "      <td>39728.0</td>\n",
       "      <td>21.976804</td>\n",
       "      <td>1.827637</td>\n",
       "      <td>11.764706</td>\n",
       "      <td>20.802836</td>\n",
       "      <td>21.829396</td>\n",
       "      <td>22.939068</td>\n",
       "      <td>87.311178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_excl_marks</th>\n",
       "      <td>39728.0</td>\n",
       "      <td>0.972563</td>\n",
       "      <td>2.964011</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>282.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_question_marks</th>\n",
       "      <td>39728.0</td>\n",
       "      <td>0.646018</td>\n",
       "      <td>1.497642</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_ellipses</th>\n",
       "      <td>39728.0</td>\n",
       "      <td>0.499522</td>\n",
       "      <td>1.583290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_uppercase_words</th>\n",
       "      <td>39728.0</td>\n",
       "      <td>4.877014</td>\n",
       "      <td>5.592917</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>151.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             count         mean         std        min  \\\n",
       "number_of_chars            39728.0  1311.359469  988.798970  41.000000   \n",
       "percentage_of_signs        39728.0    21.976804    1.827637  11.764706   \n",
       "number_of_excl_marks       39728.0     0.972563    2.964011   0.000000   \n",
       "number_of_question_marks   39728.0     0.646018    1.497642   0.000000   \n",
       "number_of_ellipses         39728.0     0.499522    1.583290   0.000000   \n",
       "number_of_uppercase_words  39728.0     4.877014    5.592917   0.000000   \n",
       "\n",
       "                                  25%         50%          75%           max  \n",
       "number_of_chars            699.000000  971.500000  1596.000000  13704.000000  \n",
       "percentage_of_signs         20.802836   21.829396    22.939068     87.311178  \n",
       "number_of_excl_marks         0.000000    0.000000     1.000000    282.000000  \n",
       "number_of_question_marks     0.000000    0.000000     1.000000     35.000000  \n",
       "number_of_ellipses           0.000000    0.000000     0.000000     48.000000  \n",
       "number_of_uppercase_words    1.000000    3.000000     6.000000    151.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de004f2a-da44-4a00-b6b8-129cd73b4272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate IQR for column 'number_of_chars'\n",
    "Q1 = reviews_df['number_of_chars'].quantile(0.25)\n",
    "Q3 = reviews_df['number_of_chars'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# identify outliers\n",
    "threshold = 1.5\n",
    "outliers = reviews_df[(reviews_df['number_of_chars'] < Q1 - threshold * IQR) | (reviews_df['number_of_chars'] > Q3 + threshold * IQR)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "270e50b0-e219-4763-b0c6-82f76881ad25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2958"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "613edaa8-06d2-4481-a7ba-4834bcf334e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36770"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.drop(outliers.index, inplace=True)\n",
    "len(reviews_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8108acff-c064-4c7b-9302-d68f5cc9998a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>number_of_chars</th>\n",
       "      <td>36770.0</td>\n",
       "      <td>1094.826435</td>\n",
       "      <td>595.737973</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>685.000000</td>\n",
       "      <td>918.000000</td>\n",
       "      <td>1393.000000</td>\n",
       "      <td>2941.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percentage_of_signs</th>\n",
       "      <td>36770.0</td>\n",
       "      <td>22.011077</td>\n",
       "      <td>1.863173</td>\n",
       "      <td>11.764706</td>\n",
       "      <td>20.813033</td>\n",
       "      <td>21.868365</td>\n",
       "      <td>23.006231</td>\n",
       "      <td>87.311178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_excl_marks</th>\n",
       "      <td>36770.0</td>\n",
       "      <td>0.909872</td>\n",
       "      <td>2.880267</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>282.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_question_marks</th>\n",
       "      <td>36770.0</td>\n",
       "      <td>0.548545</td>\n",
       "      <td>1.281312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_ellipses</th>\n",
       "      <td>36770.0</td>\n",
       "      <td>0.463204</td>\n",
       "      <td>1.469358</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_uppercase_words</th>\n",
       "      <td>36770.0</td>\n",
       "      <td>4.372042</td>\n",
       "      <td>4.524514</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>122.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             count         mean         std        min  \\\n",
       "number_of_chars            36770.0  1094.826435  595.737973  41.000000   \n",
       "percentage_of_signs        36770.0    22.011077    1.863173  11.764706   \n",
       "number_of_excl_marks       36770.0     0.909872    2.880267   0.000000   \n",
       "number_of_question_marks   36770.0     0.548545    1.281312   0.000000   \n",
       "number_of_ellipses         36770.0     0.463204    1.469358   0.000000   \n",
       "number_of_uppercase_words  36770.0     4.372042    4.524514   0.000000   \n",
       "\n",
       "                                  25%         50%          75%          max  \n",
       "number_of_chars            685.000000  918.000000  1393.000000  2941.000000  \n",
       "percentage_of_signs         20.813033   21.868365    23.006231    87.311178  \n",
       "number_of_excl_marks         0.000000    0.000000     1.000000   282.000000  \n",
       "number_of_question_marks     0.000000    0.000000     1.000000    25.000000  \n",
       "number_of_ellipses           0.000000    0.000000     0.000000    48.000000  \n",
       "number_of_uppercase_words    1.000000    3.000000     6.000000   122.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd91b810-98a9-410f-b8c4-1785d3f9d46e",
   "metadata": {},
   "source": [
    "# Text preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d0e73c-db87-4eac-88ed-5ac10bc6564a",
   "metadata": {},
   "source": [
    "## Punctuation and numbers processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5278ba0-a8c4-462a-ac9f-1a6ecf7b15ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "PUNCT_TO_REMOVE = string.punctuation\n",
    "\n",
    "reviews_df['cleaned_review'] = reviews_df['review'].apply(lambda x: x.replace('<br />', ' ')) \\\n",
    "                                           .apply(lambda x: x.translate(str.maketrans('', '', PUNCT_TO_REMOVE))) \\\n",
    "                                           .apply(lambda x: re.sub(r'[0-9]+', '', x)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb909a6d-9c61-4500-a852-70524729c941",
   "metadata": {},
   "source": [
    "## Stop-words removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4388dd3e-4d52-417a-b6c2-3cf57c83cb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ekaterina_Dul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'A',\n",
       " 'About',\n",
       " 'Above',\n",
       " 'After',\n",
       " 'Again',\n",
       " 'Against',\n",
       " 'Ain',\n",
       " 'All',\n",
       " 'Am',\n",
       " 'An',\n",
       " 'And',\n",
       " 'Any',\n",
       " 'Are',\n",
       " 'Aren',\n",
       " \"Aren'T\",\n",
       " 'As',\n",
       " 'At',\n",
       " 'Be',\n",
       " 'Because',\n",
       " 'Been',\n",
       " 'Before',\n",
       " 'Being',\n",
       " 'Below',\n",
       " 'Between',\n",
       " 'Both',\n",
       " 'But',\n",
       " 'By',\n",
       " 'Can',\n",
       " 'Couldn',\n",
       " \"Couldn'T\",\n",
       " 'D',\n",
       " 'Did',\n",
       " 'Didn',\n",
       " \"Didn'T\",\n",
       " 'Do',\n",
       " 'Does',\n",
       " 'Doesn',\n",
       " \"Doesn'T\",\n",
       " 'Doing',\n",
       " 'Don',\n",
       " \"Don'T\",\n",
       " 'Down',\n",
       " 'During',\n",
       " 'Each',\n",
       " 'Few',\n",
       " 'For',\n",
       " 'From',\n",
       " 'Further',\n",
       " 'Had',\n",
       " 'Hadn',\n",
       " \"Hadn'T\",\n",
       " 'Has',\n",
       " 'Hasn',\n",
       " \"Hasn'T\",\n",
       " 'Have',\n",
       " 'Haven',\n",
       " \"Haven'T\",\n",
       " 'Having',\n",
       " 'He',\n",
       " 'Her',\n",
       " 'Here',\n",
       " 'Hers',\n",
       " 'Herself',\n",
       " 'Him',\n",
       " 'Himself',\n",
       " 'His',\n",
       " 'How',\n",
       " 'I',\n",
       " 'If',\n",
       " 'In',\n",
       " 'Into',\n",
       " 'Is',\n",
       " 'Isn',\n",
       " \"Isn'T\",\n",
       " 'It',\n",
       " \"It'S\",\n",
       " 'Its',\n",
       " 'Itself',\n",
       " 'Just',\n",
       " 'Ll',\n",
       " 'M',\n",
       " 'Ma',\n",
       " 'Me',\n",
       " 'Mightn',\n",
       " \"Mightn'T\",\n",
       " 'More',\n",
       " 'Most',\n",
       " 'Mustn',\n",
       " \"Mustn'T\",\n",
       " 'My',\n",
       " 'Myself',\n",
       " 'Needn',\n",
       " \"Needn'T\",\n",
       " 'No',\n",
       " 'Nor',\n",
       " 'Not',\n",
       " 'Now',\n",
       " 'O',\n",
       " 'Of',\n",
       " 'Off',\n",
       " 'On',\n",
       " 'Once',\n",
       " 'Only',\n",
       " 'Or',\n",
       " 'Other',\n",
       " 'Our',\n",
       " 'Ours',\n",
       " 'Ourselves',\n",
       " 'Out',\n",
       " 'Over',\n",
       " 'Own',\n",
       " 'Re',\n",
       " 'S',\n",
       " 'Same',\n",
       " 'Shan',\n",
       " \"Shan'T\",\n",
       " 'She',\n",
       " \"She'S\",\n",
       " 'Should',\n",
       " \"Should'Ve\",\n",
       " 'Shouldn',\n",
       " \"Shouldn'T\",\n",
       " 'So',\n",
       " 'Some',\n",
       " 'Such',\n",
       " 'T',\n",
       " 'Than',\n",
       " 'That',\n",
       " \"That'Ll\",\n",
       " 'The',\n",
       " 'Their',\n",
       " 'Theirs',\n",
       " 'Them',\n",
       " 'Themselves',\n",
       " 'Then',\n",
       " 'There',\n",
       " 'These',\n",
       " 'They',\n",
       " 'This',\n",
       " 'Those',\n",
       " 'Through',\n",
       " 'To',\n",
       " 'Too',\n",
       " 'Under',\n",
       " 'Until',\n",
       " 'Up',\n",
       " 'Ve',\n",
       " 'Very',\n",
       " 'Was',\n",
       " 'Wasn',\n",
       " \"Wasn'T\",\n",
       " 'We',\n",
       " 'Were',\n",
       " 'Weren',\n",
       " \"Weren'T\",\n",
       " 'What',\n",
       " 'When',\n",
       " 'Where',\n",
       " 'Which',\n",
       " 'While',\n",
       " 'Who',\n",
       " 'Whom',\n",
       " 'Why',\n",
       " 'Will',\n",
       " 'With',\n",
       " 'Won',\n",
       " \"Won'T\",\n",
       " 'Wouldn',\n",
       " \"Wouldn'T\",\n",
       " 'Y',\n",
       " 'You',\n",
       " \"You'D\",\n",
       " \"You'Ll\",\n",
       " \"You'Re\",\n",
       " \"You'Ve\",\n",
       " 'Your',\n",
       " 'Yours',\n",
       " 'Yourself',\n",
       " 'Yourselves',\n",
       " 'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "STOPWORDS = STOPWORDS.union(set([w.title() for w in STOPWORDS]))\n",
    "\n",
    "STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e045329a-1a7d-4ec8-8d3d-3dc52e361914",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df['cleaned_review'] = reviews_df['cleaned_review'].apply(lambda x: \" \".join([word for word in x.split() if word not in STOPWORDS]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6c96894-ddcc-4616-ba1c-2bf5e4a41e58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     caught little gem totally accident back reviva...\n",
       "1     cant believe let movie accomplish favor friend...\n",
       "2     spoiler alert gets nerve people remake use ter...\n",
       "3     theres one thing Ive learnt watching George Ro...\n",
       "4     remember theaters reviews said horrible Well d...\n",
       "5     Opera US title terror opera somewhat letdown D...\n",
       "6     Heard film long ago finally found ebay five bu...\n",
       "8     worth mentioning omitted reviews read subtext ...\n",
       "9     Darling Lili fantastic far one favorite films ...\n",
       "10    Twentieth CenturyFox made ton Mr Moto films Ho...\n",
       "Name: cleaned_review, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df['cleaned_review'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7e95be-ffa6-4c44-b4a1-0f79db61ea90",
   "metadata": {},
   "source": [
    "## Tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc44eed3-18b6-4c8f-b15b-f83a4317cf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to be applied to each element\n",
    "def tokenize_text(text):\n",
    "    return nltk.word_tokenize(text)\n",
    "\n",
    "# Function to handle multiprocessing\n",
    "def parallelize_dataframe(df, func, n_cores=8):\n",
    "    df_split = np.array_split(df, n_cores)\n",
    "    pool = Pool(n_cores)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df\n",
    "\n",
    "# Helper function to apply to each split\n",
    "def apply_tokenize(df):\n",
    "    df['tokenized_review'] = df['cleaned_review'].apply(tokenize_text)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6c9db4a-4c00-4520-a4ec-1161818fed73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function in parallel\n",
    "# reviews_df = parallelize_dataframe(reviews_df, apply_tokenize)\n",
    "\n",
    "# reviews_df['tokenized_review'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0702d8c1-db32-4c40-a938-39ab958bd445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92393f5-d23b-4f88-89dd-eabd3828d5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016faf53-7514-4ef9-ac2d-97f3ac1489c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
